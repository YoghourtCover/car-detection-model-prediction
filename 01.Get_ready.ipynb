{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Environment\n",
    "\n",
    "First, I should build the environment that I will make the development on. I have used anaconda environment based on Python 3.5v. \n",
    "\n",
    "After I create the environment based on Python 3.5, I can install these libraries by using **conda install** command. These libraries can be reached via on the website of Anaconda. \n",
    "\n",
    "```\n",
    "# It creates the environment\n",
    "conda create -n hadibakalim_env python=3.5\n",
    "\n",
    "# It activates the environment\n",
    "source activate hadibakalim_env\n",
    "\n",
    "# Install the libraries\n",
    "conda install -c menpo opencv3\n",
    "conda install -c conda-forge matplotlib \n",
    "conda install -c anaconda keras-gpu \n",
    "conda install -c anaconda tensorflow-gpu\n",
    "conda install -c conda-forge h5py \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Libraries\n",
    "\n",
    "I should add the libraries that I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir\n",
    "import numpy as np # library for scientific computing in Python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import h5py # for reading and writing HDF5 files from Python.\n",
    "import cv2 # OpenCV 3.2\n",
    "from random import randint # to generate random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collect many images from online sources and categorize them in files which their names are related to classes. In this work, I have seven classes. I will give a name to every single image starting with **class label** and **index number** like *passat0001.jpg ..... passat4014.jpg* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_image(details):\n",
    "    \"\"\" give name to images\n",
    "    details['source_path']: where the images from different classes stay\n",
    "    image_dict: dictionary includes image names of classes and labels\n",
    "    details['zero_base']: To start with a certain base 0\n",
    "    \"\"\"\n",
    "    # Create the dictionary\n",
    "    image_dict = dict(zip(details['file_name'], details['image_label']))\n",
    "    \n",
    "    # Do it for every file\n",
    "    for path_img, image_name in image_dict.items():\n",
    "    \n",
    "        # Create a path list contains the files\n",
    "        file_names = sorted(os.listdir(details['source_path'] + path_img + '/'))\n",
    "    \n",
    "        # Do it for every file\n",
    "        for index, name in enumerate(file_names):\n",
    "            os.rename(details['source_path'] + path_img + '/' + name, \\\n",
    "                      details['source_path'] + path_img + '/' + image_name + \\\n",
    "                      str(index).zfill(details['zero_base'])+ details['image_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {}\n",
    "\n",
    "# I add the names of the files that contains images\n",
    "details['file_name'] = ['VW-Passat', 'RENO-Fluence', 'FIAT-Linea', 'VW-Polo',\\\n",
    "                         'RENO-Toros', 'FIAT-Dogan', 'OtherClass']\n",
    "\n",
    "# I label them like that\n",
    "details['image_label'] = ['passat', 'fluence', 'linea', 'polo', 'toros', 'dogan', 'other']\n",
    "\n",
    "# It is source path of files. This main path includes the files that I name at first line \n",
    "details['source_path'] = '../main/source/path/'\n",
    "\n",
    "# It pads the string on the left with zeros\n",
    "details['zero_base'] = 4\n",
    "\n",
    "# It defines the image type\n",
    "details['image_type'] = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_image(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary\n",
    "\n",
    "Here I create a dictinary that will save image names corresponding to class file.\n",
    "\n",
    "Keys are the file names that in *details['file_name']*.\n",
    "Values are the lists that includes image names for every key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(details):\n",
    "    \n",
    "    # It take all the entries under the source path\n",
    "    contents = os.listdir(details['source_path'])\n",
    "    \n",
    "    # It keeps only the files under the source path\n",
    "    classes = [each for each in contents if os.path.isdir(details['source_path'] + each)]\n",
    "    print(classes)\n",
    "    \n",
    "    # Create a dictionary that will keep the lists\n",
    "    database_detail = {}\n",
    "\n",
    "    # For every file\n",
    "    for each in classes:\n",
    "\n",
    "        # Create a list that will keep the image names\n",
    "        database_list = []\n",
    "\n",
    "        # If the file under the source path matches with the one I enter in details['file_name']\n",
    "        if len(os.listdir(details['source_path'] + each)) > 0 and each in details['file_name']:   \n",
    "\n",
    "            class_path = details['source_path'] + each\n",
    "            files = os.listdir(class_path)\n",
    "\n",
    "            # Sort ascending \n",
    "            files.sort(key=lambda f: int(''.join(filter(str.isdigit, f))) )\n",
    "\n",
    "            # Add every image to the related list\n",
    "            for img in files:\n",
    "                database_list.append(img)\n",
    "\n",
    "            # each is a file name, database list is a list that includes image names related to that file\n",
    "            database_detail[each] = database_list\n",
    "            \n",
    "    return database_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details['database_detail'] = createDict(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes we have\n",
    "print(len(details['database_detail']))\n",
    "# Number of images which belongs to every classes\n",
    "print(list(map(len, database_detail.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Remove the images have unwanted size\n",
    "\n",
    "If your dataset has kind of 95% same shape and you want to get rid of the others, you can use this snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAnormalShape(database_detail, hdf5_path, save_img_size):\n",
    "    # Keep the file names as a list\n",
    "    class_list = list(details['database_detail'].keys())\n",
    "    \n",
    "    for class_name in class_list:\n",
    "        # path for every file\n",
    "        path = details['source_path'] + class_name\n",
    "        \n",
    "        for index, each in enumerate(details['database_detail'][class_name]):\n",
    "            \n",
    "            img_path =  path + '/' + each\n",
    "            # Read the image\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # Check if it matches with wanted size\n",
    "            if img.shape != details['save_img_size']:\n",
    "                # If not, remove from dictionary\n",
    "                details['database_detail'][class_name].remove(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details['save_img_size'] = (300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeAnormalShape(details['database_detail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes we have\n",
    "print(len(details['database_detail']))\n",
    "# Number of images which belongs to every classes\n",
    "print(list(map(len, details['database_detail'].values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Classes to HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classFiles2hdf5(database_detail):\n",
    "        \n",
    "    for class_name in details['file_name']:\n",
    "        \n",
    "        hdf5_path = details['save_path'] + details['prefix'] + class_name + '.hdf5'\n",
    "        \n",
    "        if not os.path.exists(hdf5_path):\n",
    "            os.mknod(hdf5_path)\n",
    "            \n",
    "        # opening like this, solves the problem of 'Unable to truncate a file which is already open'\n",
    "        with h5py.File(hdf5_path,'w') as hdf5_file:\n",
    "\n",
    "            data_shape = (len(database_detail[class_name]), details['save_img_size'][0], \\\n",
    "                          details['save_img_size'][1], details['save_img_size'][2])\n",
    "            hdf5_file.create_dataset(details['hdf5_dataset_label'][0], data_shape, np.uint8)\n",
    "            \n",
    "            hdf5_file.create_dataset(details['hdf5_dataset_label'][1], (len(database_detail[class_name]), ), np.uint8)\n",
    "            hdf5_file[details['hdf5_dataset_label'][1]][...] = details['file_name'].index(class_name)\n",
    "            \n",
    "            # We will add the hotlabel on next part\n",
    "            \n",
    "            # It is good to save the image with its name for easing to find when it is needed\n",
    "            dt = h5py.special_dtype(vlen=bytes)\n",
    "            hdf5_file.create_dataset(details['hdf5_dataset_label'][3], (len(database_detail[class_name]), ), dtype=dt)\n",
    "\n",
    "            for index, each in enumerate(database_detail[class_name]):\n",
    "                                     \n",
    "                img_path = details['source_path'] + class_name + '/' + each\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      \n",
    "                hdf5_file[details['hdf5_dataset_label'][0]][index, ...] = img[None]\n",
    "                hdf5_file[details['hdf5_dataset_label'][3]][index, ...] = each\n",
    "                # We don't need to close to file like using hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "details['hdf5_dataset_label'] = ['batch', 'label', 'hotlabel', 'img_name']\n",
    "\n",
    "# The image sizes that hdf5 files have\n",
    "details['save_img_size'] = (300, 300, 3)\n",
    "\n",
    "# We will save the hdf5 file under this path\n",
    "details['save_path'] = 'save/to/this/path/'\n",
    "\n",
    "# I want to give a prefix for hdf5 files, use it if you want\n",
    "# Live it empty if you don't want to add a prefix\n",
    "details['prefix'] = 'orig_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function that turn files into hdf5 files\n",
    "classFiles2hdf5(details['database_detail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test(test_path, hdf5_dataset, image_label):\n",
    "      \n",
    "    # open the hdf5 file\n",
    "    with h5py.File(test_path,'r') as hdf5_file:\n",
    "        \n",
    "        # Total number of samples\n",
    "        X_train = hdf5_file[hdf5_dataset[0]]\n",
    "        Y_train = hdf5_file[hdf5_dataset[1]]\n",
    "        img_name = hdf5_file[hdf5_dataset[3]]\n",
    "\n",
    "        # randomly pick a number for index\n",
    "        random_index = randint(0,len(Y_train))    \n",
    "\n",
    "        img = X_train[random_index]\n",
    "        print('Image name : ' + str(img_name[random_index]))\n",
    "        print('Length : ' + str(len(X_train)))\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        print('Label_class : ' + str(Y_train[random_index]))\n",
    "        print('Label_class : ' + image_label[Y_train[random_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the hdf5 files\n",
    "test_path = 'call/from/save/path/orig_RENO-Fluence.hdf5'\n",
    "\n",
    "show_test(test_path, details['hdf5_dataset_label'], details['image_label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
